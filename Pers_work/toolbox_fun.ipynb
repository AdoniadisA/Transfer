{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import panda as pd\n",
    "\n",
    "\n",
    "def raster(spike_dict,unitidx,stim_dict,eventidx,event_times,rasterfs):\n",
    "    # spike_dict : spikes of a hole recording\n",
    "    # unitidx : unit's spikes we want to look at\n",
    "    # stim_dict : stimuli, used for the names of the events\n",
    "    # eventidx : idx of event we want to look at\n",
    "    # rasterfs : spike frequency\n",
    "    import numpy as np\n",
    "    \n",
    "    stimevents=list(stim_dict.keys())\n",
    "    cellids=list(spike_dict.keys())\n",
    "    print('hey')\n",
    "    event_name=stimevents[eventidx]\n",
    "    cellid=cellids[unitidx]\n",
    "    \n",
    "    binlen=1.0/rasterfs\n",
    "    h=np.array([])\n",
    "    ff = (event_times['name']==event_name)\n",
    "    ## pull out each epoch from the spike times, generate a raster of spike rate\n",
    "    for i,d in event_times.loc[ff].iterrows():\n",
    "        #print(\"{0}-{1}\".format(d['start'],d['end']))\n",
    "        edges=np.arange(d['start'],d['end']+binlen,binlen)\n",
    "        th,e=np.histogram(spike_dict[cellid],edges)\n",
    "\n",
    "        #print(\"{0}-{1}: {2}\".format(edges[0],edges[1],sum((spike_dict[cellid]>edges[0]) & (spike_dict[cellid]<edges[1]))))\n",
    "        th=np.reshape(th,[1,-1])\n",
    "        if h.size==0:\n",
    "            # lazy hack: intialize the raster matrix without knowing how many bins it will require\n",
    "            h=th\n",
    "        else:\n",
    "            # concatenate this repetition, making sure binned length matches\n",
    "            if th.shape[1]<h.shape[1]:\n",
    "                h=np.concatenate((h,np.zeros([1,h.shape[1]])),axis=0)\n",
    "                h[-1,:]=np.nan\n",
    "                h[-1,:th.shape[1]]=th\n",
    "            else:\n",
    "                h=np.concatenate((h,th[:,:h.shape[1]]),axis=0)\n",
    "    return h\n",
    "\n",
    "def getTrainTestTimes(event_times,trainNb,testNb):\n",
    "    # event_times : timings of events \n",
    "    # trainNb : number of stimuli presented for the trains\n",
    "    # testNb : number of stimuli presented for the tests\n",
    "    \n",
    "    wavEvents = event_times[event_times['name'].str.contains('.wav')]\n",
    "    occurences =  wavEvents['name'].value_counts(sort=True)\n",
    "\n",
    "    Train_names = list(occurences[occurences==trainNb].index)\n",
    "    Test_names = list(occurences[occurences==testNb].index)\n",
    "\n",
    "\n",
    "    Train_times = pd.DataFrame(columns={'name','start','end'})\n",
    "    Train_times = Train_times[['name','start','end']] #Order the columns\n",
    "    Test_times = Train_times.copy()\n",
    "\n",
    "    #Get stimuli onset and offset times for trains\n",
    "    trial_indexs = event_times['name'][event_times['name']=='TRIAL'].index\n",
    "    idx1 = 0; idx2 = 0;\n",
    "    for trial_idx in trial_indexs:\n",
    "        name = event_times.iloc[trial_idx+1]['name']\n",
    "        if name in Train_names :\n",
    "            Train_times.at[idx1,'name'] = name\n",
    "            Train_times.at[idx1,'start'] = event_times.iloc[trial_idx+3]['end']\n",
    "            Train_times.at[idx1,'end'] = event_times.iloc[trial_idx+4]['start']\n",
    "            idx1 +=1\n",
    "        elif name in Test_names :\n",
    "            Test_times.at[idx2,'name'] = name\n",
    "            Test_times.at[idx2,'start'] = event_times.iloc[trial_idx+3]['end']\n",
    "            Test_times.at[idx2,'end'] = event_times.iloc[trial_idx+4]['start']\n",
    "            idx2 +=1\n",
    "        else : \n",
    "            raise ValueError('Neither a Test nor a Train stimuli name')\n",
    "\n",
    "    Train_times = Train_times.sort_values('name')\n",
    "    Test_times = Test_times.sort_values('name')\n",
    "\n",
    "    return Train_times,Test_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook run_fun.ipynb to script\n",
      "[NbConvertApp] Writing 793 bytes to run_fun.py\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
